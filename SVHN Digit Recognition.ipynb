{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d707967",
   "metadata": {},
   "source": [
    "# SVHN Digit Recognition\n",
    "## Katherine King"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f31e0",
   "metadata": {},
   "source": [
    "SVHN is a dataset of street view house numbers obtained from Google (http://ufldl.stanford.edu/housenumbers/). Recognizing digits in SVHN is more difficult than in MNIST. \n",
    "Reference: Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu and A. Y. Ng. \"Reading Digits in Natural Images with Unsupervised Feature Learning\". NIPS Workshop on Deep Learning and Unsupervised Feature Learning, 2011."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612bb68d",
   "metadata": {},
   "source": [
    "This notebook contains an end-to-end workflow for building, training, validating, evaluating and saving multiclass MLP and CNN models using the Sequential API in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b473584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b601f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load the dataset\n",
    "\n",
    "train = loadmat('data/train_32x32.mat')\n",
    "test = loadmat('data/test_32x32.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9210ffaf",
   "metadata": {},
   "source": [
    "# Exploration and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b9a8b9",
   "metadata": {},
   "source": [
    "1. Extract the training and testing images and labels.\n",
    "2. Select and display a random sample of images and corresponding labels from the dataset.\n",
    "3. Convert the training and test images to grayscale by taking the average across all color channels for each pixel, retaining the channel dimension (now size=1). \n",
    "4. Select and display a random sample of the grayscale images and corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbae5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train['X'] / 255.\n",
    "y_train = train['y']\n",
    "x_test = test['X'] / 255.\n",
    "y_test = test['y']\n",
    "y_train = np.where(y_train==10, 0, y_train)\n",
    "y_test = np.where(y_test==10, 0, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04532a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.moveaxis(x_train, -1, 0)\n",
    "x_test = np.moveaxis(x_test, -1 , 0)\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = random.sample(range(0, x_train.shape[0]), 10 )\n",
    "fig, ax = plt.subplots(1, 10, figsize=(10,1))\n",
    "\n",
    "for i in range(10):\n",
    "    ax[i].set_axis_off()\n",
    "    ax[i].imshow(x_train[indices[i]])\n",
    "    ax[i].set_title(y_train[indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead79aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_gs = np.mean(x_train, -1, keepdims=True)\n",
    "x_test_gs = np.mean(x_test, -1, keepdims=True)\n",
    "x_train_gs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = random.sample(range(0, x_train_gs.shape[0]), 10 )\n",
    "fig, ax = plt.subplots(1, 10, figsize=(10,1))\n",
    "\n",
    "for i in range(10):\n",
    "    ax[i].set_axis_off()\n",
    "    ax[i].imshow(x_train_gs[indices[i],:,:,0], cmap='gray')\n",
    "    ax[i].set_title(y_train[indices[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084125e3",
   "metadata": {},
   "source": [
    "# MLP neural network classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bc7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlp_model():\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=x_train[0].shape),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "model=get_mlp_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02516a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e4e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimization='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258ba1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'checkpoint/best_model'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path,\n",
    "                     save_best_only=True,\n",
    "                     save_weights_only=True,\n",
    "                     verbose=False,\n",
    "                     save_freq='epoch',\n",
    "                     monitor='val_loss',\n",
    "                     mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7003b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=4)\n",
    "history = model.fit(x_train, y_train, epochs=30, batch_size=64, \n",
    "                    verbose=1, validation_split=0.1, callbacks=[checkpoint, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082f9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss Vs Epochs\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy Vs Epochs\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aafac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=False)\n",
    "print(f\"Test Loss is {test_loss}\")\n",
    "print(f\"Test Accuracy is {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4023b67",
   "metadata": {},
   "source": [
    "# CNN neural network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621d4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "    cnn_model = Sequential([\n",
    "        Conv2D(64, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        MaxPooling2D((3,3)),\n",
    "        BatchNormalization(), \n",
    "        Conv2D(16, (3,3), activation='relu'),\n",
    "        MaxPooling2D((3,3)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return cnn_model  \n",
    "cnn_model = get_cnn_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimization='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6225261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_checkpoint_path = 'cnn_checkpoint/best_cnn_model'\n",
    "cnn_checkpoint = ModelCheckpoint(cnn_checkpoint_path,\n",
    "                     save_best_only=True,\n",
    "                     save_weights_only=True,\n",
    "                     verbose=False,\n",
    "                     save_freq='epoch',\n",
    "                     monitor='val_loss',\n",
    "                     mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=3)\n",
    "cnn_history = cnn_model.fit(x_train, y_train, epochs=30, batch_size=64, \n",
    "                    verbose=1, validation_split=0.1, callbacks=[cnn_checkpoint, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3945a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cnn_history.history['loss'])\n",
    "plt.plot(cnn_history.history['val_loss'])\n",
    "plt.title(\"Loss Vs Epochs\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cnn_history.history['accuracy'])\n",
    "plt.plot(cnn_history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy Vs Epochs\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d5ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(f\"Test Loss is {cnn_test_loss}\")\n",
    "print(f\"Test Accuracy is {cnn_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3768bf",
   "metadata": {},
   "source": [
    "# Get model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp_model = get_mlp_model()\n",
    "best_mlp_model.load_weights('checkpoint/best_model')\n",
    "best_cnn_model = get_cnn_model()\n",
    "best_cnn_model.load_weights('cnn_checkpoint/best_cnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6110a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_predictive_distribution(model):\n",
    "\n",
    "    num_test_images = x_test.shape[0]\n",
    "\n",
    "    random_inx = np.random.choice(num_test_images, 5)\n",
    "    random_test_images = x_test[random_inx, ...]\n",
    "    random_test_labels = y_test[random_inx, ...]\n",
    "\n",
    "    fig, axes = plt.subplots(5, 2, figsize=(16, 12))\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=-0.2)\n",
    "\n",
    "    predictions = model.predict(random_test_images)\n",
    "    \n",
    "    for i, (prediction, image, label) in enumerate(zip(predictions, random_test_images, random_test_labels)):\n",
    "        axes[i, 0].imshow(np.squeeze(image))\n",
    "        axes[i, 0].get_xaxis().set_visible(False)\n",
    "        axes[i, 0].get_yaxis().set_visible(False)\n",
    "        axes[i, 0].text(10., -1.5, f'Digit {label}')\n",
    "        axes[i, 1].bar(np.arange(len(prediction)), prediction)\n",
    "        axes[i, 1].set_xticks(np.arange(len(prediction)))\n",
    "        axes[i, 1].set_title(f\"Model prediction: {np.argmax(prediction)}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add96fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_predictive_distribution(best_mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b80a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_predictive_distribution(best_cnn_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
