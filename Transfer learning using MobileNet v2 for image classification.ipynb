{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a841bf01",
   "metadata": {},
   "source": [
    "### Transfer learning using MobileNet v2 for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import  Sequential, Model\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input, Dropout\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e238ffad",
   "metadata": {},
   "source": [
    "The Dogs vs Cats dataset\n",
    "The Dogs vs Cats dataset was used for a 2013 Kaggle competition. It consists of 25000 images containing either a cat or a dog. We will only use a subset of 600 images and labels. The dataset is a subset of a much larger dataset of 3 million photos that were originally used as a CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart), referred to as “Asirra” or Animal Species Image Recognition for Restricting Access.\n",
    "\n",
    "J. Elson, J. Douceur, J. Howell, and J. Saul. \"Asirra: A CAPTCHA that Exploits Interest-Aligned Manual Image Categorization.\" Proceedings of 14th ACM Conference on Computer and Communications Security (CCS), October 2007.\n",
    "Your goal is to train a classifier model using part of a pre-trained image classifier, using the principle of transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e4226",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = np.load('data/images_train.npy') / 255.\n",
    "images_valid = np.load('data/images_valid.npy') / 255.\n",
    "images_test = np.load('data/images_test.npy') / 255.\n",
    "\n",
    "labels_train = np.load('data/labels_train.npy')\n",
    "labels_valid = np.load('data/labels_valid.npy')\n",
    "labels_test = np.load('data/labels_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9772c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} training data examples\".format(images_train.shape[0]))\n",
    "print(\"{} validation data examples\".format(images_valid.shape[0]))\n",
    "print(\"{} test data examples\".format(images_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few images and labels\n",
    "\n",
    "class_names = np.array(['Dog', 'Cat'])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "inx = np.random.choice(images_train.shape[0], 15, replace=False)\n",
    "for n, i in enumerate(inx):\n",
    "    ax = plt.subplot(3,5,n+1)\n",
    "    plt.imshow(images_train[i])\n",
    "    plt.title(class_names[labels_train[i]])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build CNN benchmark model\n",
    "def get_benchmark_model(input_shape):\n",
    "    \"\"\"\n",
    "    This function should build and compile a CNN model according to the above specification,\n",
    "    using the functional API. The function takes input_shape as an argument, which should be\n",
    "    used to specify the shape in the Input layer.\n",
    "    Your function should return the model.\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    conv = Conv2D(32, (3,3), activation='relu', padding='SAME')(inp)\n",
    "    conv = Conv2D(32, (3,3), activation='relu', padding='SAME')(conv)\n",
    "    mp = MaxPooling2D((2,2))(conv)\n",
    "    conv = Conv2D(64, (3,3), activation='relu', padding='SAME')(mp)\n",
    "    conv = Conv2D(64, (3,3), activation='relu', padding='SAME')(conv)\n",
    "    mp = MaxPooling2D((2,2))(conv)\n",
    "    conv = Conv2D(128, (3,3), activation='relu', padding='SAME')(mp)\n",
    "    conv = Conv2D(128, (3,3), activation='relu', padding='SAME')(conv)\n",
    "    mp = MaxPooling2D((2,2))(conv)\n",
    "    flatten = Flatten()(mp)\n",
    "    dense = Dense(128, activation='relu')(flatten)\n",
    "    output = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inp, outputs=output)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b988e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_model = get_benchmark_model(images_train[0].shape)\n",
    "benchmark_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "history_benchmark = benchmark_model.fit(images_train, labels_train, epochs=10, batch_size=32,\n",
    "                                        validation_data=(images_valid, labels_valid), \n",
    "                                        callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add414cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "try:\n",
    "    plt.plot(history_benchmark.history['accuracy'])\n",
    "    plt.plot(history_benchmark.history['val_accuracy'])\n",
    "except KeyError:\n",
    "    plt.plot(history_benchmark.history['acc'])\n",
    "    plt.plot(history_benchmark.history['val_acc'])\n",
    "plt.title('Accuracy vs. epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history_benchmark.history['loss'])\n",
    "plt.plot(history_benchmark.history['val_loss'])\n",
    "plt.title('Loss vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d390f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_test_loss, benchmark_test_acc = benchmark_model.evaluate(images_test, labels_test, verbose=0)\n",
    "print(\"Test loss: {}\".format(benchmark_test_loss))\n",
    "print(\"Test accuracy: {}\".format(benchmark_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8092ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-trained MobileNet V2 model, available to download from Keras Applications https://keras.io/api/applications/#mobilenetv2\n",
    "def load_pretrained_MobileNetV2(path):\n",
    "    \"\"\"\n",
    "    This function takes a path as an argument, and uses it to \n",
    "    load the full MobileNetV2 pretrained model from the path.\n",
    "    Your function should return the loaded model.\n",
    "    \"\"\"\n",
    "\n",
    "    return load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18178fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = load_pretrained_MobileNetV2('models/MobileNetV2.h5')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d034a",
   "metadata": {},
   "source": [
    "Use the pre-trained model as a feature extractor:\n",
    "- removing the final layer of the network\n",
    "- replace it with new, untrained classifier layers\n",
    "- create a new model that has the same input tensor as the MobileNetV2 model\n",
    "- use the output tensor from the layer with name global_average_pooling2d_6 as the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = remove_head(base_model)\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f31b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_classifier_head(feature_extractor_model):\n",
    "    \"\"\"\n",
    "    This function takes the feature extractor model as an argument, and should create\n",
    "    and return a new model according to the above specification.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        feature_extractor_model, \n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b20a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = add_new_classifier_head(feature_extractor)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_pretrained_weights(model):\n",
    "    \"\"\"\n",
    "    This function should freeze the weights of the pretrained base model.\n",
    "    Your function should return the model with frozen weights.\n",
    "    \"\"\"\n",
    "    model.layers[0].trainable=False\n",
    "    \n",
    "    #model = tf.keras.Model(inputs=inp, outputs=output)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['acc'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb343845",
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_new_model = freeze_pretrained_weights(new_model)\n",
    "frozen_new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f49235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "history_frozen_new_model = frozen_new_model.fit(images_train, labels_train, epochs=10, batch_size=32,\n",
    "                                                validation_data=(images_valid, labels_valid), \n",
    "                                                callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2725fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "try:\n",
    "    plt.plot(history_frozen_new_model.history['accuracy'])\n",
    "    plt.plot(history_frozen_new_model.history['val_accuracy'])\n",
    "except KeyError:\n",
    "    plt.plot(history_frozen_new_model.history['acc'])\n",
    "    plt.plot(history_frozen_new_model.history['val_acc'])\n",
    "plt.title('Accuracy vs. epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history_frozen_new_model.history['loss'])\n",
    "plt.plot(history_frozen_new_model.history['val_loss'])\n",
    "plt.title('Loss vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_test_loss, new_model_test_acc = frozen_new_model.evaluate(images_test, labels_test, verbose=0)\n",
    "print(\"Test loss: {}\".format(new_model_test_loss))\n",
    "print(\"Test accuracy: {}\".format(new_model_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_train_loss = history_benchmark.history['loss'][-1]\n",
    "benchmark_valid_loss = history_benchmark.history['val_loss'][-1]\n",
    "\n",
    "try:\n",
    "    benchmark_train_acc = history_benchmark.history['acc'][-1]\n",
    "    benchmark_valid_acc = history_benchmark.history['val_acc'][-1]\n",
    "except KeyError:\n",
    "    benchmark_train_acc = history_benchmark.history['accuracy'][-1]\n",
    "    benchmark_valid_acc = history_benchmark.history['val_accuracy'][-1]\n",
    "\n",
    "new_model_train_loss = history_frozen_new_model.history['loss'][-1]\n",
    "new_model_valid_loss = history_frozen_new_model.history['val_loss'][-1]\n",
    "\n",
    "try:\n",
    "    new_model_train_acc = history_frozen_new_model.history['acc'][-1]\n",
    "    new_model_valid_acc = history_frozen_new_model.history['val_acc'][-1]\n",
    "except KeyError:\n",
    "    new_model_train_acc = history_frozen_new_model.history['accuracy'][-1]\n",
    "    new_model_valid_acc = history_frozen_new_model.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1fa97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_table = pd.DataFrame([['Training loss', benchmark_train_loss, new_model_train_loss],\n",
    "                                ['Training accuracy', benchmark_train_acc, new_model_train_acc],\n",
    "                                ['Validation loss', benchmark_valid_loss, new_model_valid_loss],\n",
    "                                ['Validation accuracy', benchmark_valid_acc, new_model_valid_acc],\n",
    "                                ['Test loss', benchmark_test_loss, new_model_test_loss],\n",
    "                                ['Test accuracy', benchmark_test_acc, new_model_test_acc]],\n",
    "                               columns=['Metric', 'Benchmark CNN', 'Transfer learning CNN'])\n",
    "comparison_table.index=['']*6\n",
    "comparison_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "preds = benchmark_model.predict(images_test)\n",
    "preds = (preds >= 0.5).astype(np.int32)\n",
    "cm = confusion_matrix(labels_test, preds)\n",
    "df_cm = pd.DataFrame(cm, index=['Dog', 'Cat'], columns=['Dog', 'Cat'])\n",
    "plt.subplot(121)\n",
    "plt.title(\"Confusion matrix for benchmark model\\n\")\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.xlabel(\"Actual\")\n",
    "\n",
    "preds = frozen_new_model.predict(images_test)\n",
    "preds = (preds >= 0.5).astype(np.int32)\n",
    "cm = confusion_matrix(labels_test, preds)\n",
    "df_cm = pd.DataFrame(cm, index=['Dog', 'Cat'], columns=['Dog', 'Cat'])\n",
    "plt.subplot(122)\n",
    "plt.title(\"Confusion matrix for transfer learning model\\n\")\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62fa05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
